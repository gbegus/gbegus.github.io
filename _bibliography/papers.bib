---
---


@article{begus20,
author={Begu\v{s}, Ga\v{s}per},    
title={Generative Adversarial Phonology: Modeling Unsupervised Phonetic and Phonological Learning With Neural Networks},      	
journal={Frontiers in Artificial Intelligence},      	
volume={3},      
pages={44},     	
year={2020},      	  
url={https://www.frontiersin.org/article/10.3389/frai.2020.00044},
html={https://www.frontiersin.org/article/10.3389/frai.2020.00044},       
doi={10.3389/frai.2020.00044},      
issn={2624-8212},   
abstract={Training deep neural networks on well-understood dependencies in speech data can provide new insights into how they learn internal representations. This paper argues that acquisition of speech can be modeled as a dependency between random space and generated speech data in the Generative Adversarial Network architecture and proposes a methodology to uncover the network's internal representations that correspond to phonetic and phonological properties. The Generative Adversarial architecture is uniquely appropriate for modeling phonetic and phonological learning because the network is trained on unannotated raw acoustic data and learning is unsupervised without any language-specific assumptions or pre-assumed levels of abstraction. A Generative Adversarial Network was trained on an allophonic distribution in English, in which voiceless stops surface as aspirated word-initially before stressed vowels, except if preceded by a sibilant [s]. The network successfully learns the allophonic alternation: the network's generated speech signal contains the conditional distribution of aspiration duration. The paper proposes a technique for establishing the network's internal representations that identifies latent variables that correspond to, for example, presence of [s] and its spectral properties. By manipulating these variables, we actively control the presence of [s] and its frication amplitude in the generated outputs. This suggests that the network learns to use latent variables as an approximation of phonetic and phonological representations. Crucially, we observe that the dependencies learned in training extend beyond the training interval, which allows for additional exploration of learning representations. The paper also discusses how the network's architecture and innovative outputs resemble and differ from linguistic behavior in language acquisition, speech disorders, and speech errors, and how well-understood dependencies in speech data can help us interpret how neural networks learn their representations.},
pdf={begusGAP.pdf},
}


@inproceedings{begusscil,
    title = "Modeling unsupervised phonetic and phonological learning in {Generative Adversarial Phonology}",
    author = "Ga\v{s}per Begu\v{s}",
    booktitle = "Proceedings of the Society for Computation in Linguistics",
    year = "2020",
    url = "https://doi.org/10.7275/nbrf-1a27",
    html = "https://doi.org/10.7275/nbrf-1a27",
    doi = "10.7275/nbrf-1a27",
    pages = "138--148",
    pdf={begusScil.pdf},
    abstract={This paper models phonetic and phonologi- cal learning as a dependency between random space and generated speech data in the Gener- ative Adversarial Neural network architecture and proposes a methodology to uncover the network’s internal representation that corre- sponds to phonetic and phonological features. A Generative Adversarial Network (Goodfel- low et al. 2014; implemented as WaveGAN for acoustic data by Donahue et al. 2019) was trained on an allophonic distribution in En- glish, where voiceless stops surface as aspi- rated word-initially before stressed vowels ex- cept if preceded by a sibilant [s]. The net- work successfully learns the allophonic alter- nation: the network’s generated speech signal contains the conditional distribution of aspira- tion duration. Additionally, the network gener- ates innovative outputs for which no evidence is available in the training data, suggesting that the network segments continuous speech sig- nal into units that can be productively recom- bined. The paper also proposes a technique for establishing the network’s internal representa- tions. We identify latent variables that directly correspond to presence of [s] in the output. By manipulating these variables, we actively con- trol the presence of [s], its frication amplitude, and spectral shape of the frication noise in the generated outputs.}
} 


@article{begus19, 
title={Post-nasal devoicing and the blurring process},
volume={55}, DOI={10.1017/S002222671800049X}, 
number={4}, 
journal={Journal of Linguistics}, 
publisher={Cambridge University Press}, 
author={Begu\v{s}, Ga\v{s}per}, 
year={2019}, pages={689–753},
html={https://www.cambridge.org/core/journals/journal-of-linguistics/article/postnasal-devoicing-and-the-blurring-process/51B1F27754D14F8BF523B905FFFE3BA1},
abstract={This paper addresses one of the most contested issues in phonology: unnatural alternations. First, non-natural phonological processes are subdivided into unmotivated and unnatural. The central topic of the paper is an unnatural process: post-nasal devoicing (PND). I collect thirteen cases of PND and argue that in all reported cases, PND does not derive from a single unnatural sound change (as claimed in some individual accounts of the data), but rather from a combination of three sound changes, each of which is phonetically motivated. I present new evidence showing that the three stages are directly historically attested in the pre-history of Yaghnobi. Based on several discussed cases, I propose a new diachronic model for explaining unnatural phenomena called the Blurring Process and point to its advantages over competing approaches (hypercorrection, perceptual enhancement, and phonetic motivation). The Blurring Process establishes general diachronic conditions for unnatural synchronic processes and can be employed to explain unnatural processes beyond PND. Additionally, I provide a proof establishing the minimal sound changes required for an unmotivated/unnatural alternation to arise. The Blurring Process and Minimal Sound Change Requirement have implications for models of typology within the Channel Bias approach. This paper thus presents a first step toward the ultimate goal of quantifying the influences of Channel Bias on phonological typology.},
}

@INPROCEEDINGS{begusnazarov18, author= {Ga\v{s}per Begu\v{s}  and Aleksei Nazarov}, title= {Gradient trends against phonetic naturalness: The case of {Tarma Quechua}}, booktitle= {NELS 48: Proceedings of the Forty-Eighth Annual Meeting of the North East Linguistic Society}, year= {2018}, editor= {Sherry Hucklebridge and Max Nelson}, volume= {1}, pages= {73-86}, publisher= {GLSA University of Massachusetts Amherst}, address= {Amherst, MA}, isbn= {978-1727605792},
pdf={begusNazarovNels.pdf},
}


@inproceedings{begus, issn= {1042-1068}, abstract= {Identifying and modeling factors that influence typology has been one of the most contested issues in phonology with two major lines of thought emerging in this discussion: the Analytic Bias (AB) and Channel Bias (CB) approaches (Moreton 2008). Empirical evidence in favor of both approaches exists, yet very few attempts have been made to model them together. This paper aims to fill this gap and proposes a new MaxEnt-compatible model of phonological typology that models both AB and CB together. The first step towards a new model of typology is to establish quantitative models of each of the subcomponents: AB and CB. To encode the AB portion of the typology, we adopt Wilson's (2006) approach of differentiating variance in the prior of a MaxEnt model of phonological learning; to encode the CB portion, we adopt Beguš's (2016) new model of typology within CB that operates with Historical Probabilities of Alternations and an estimation method called Bootstrapping Sound Changes. This paper proposes a new model of typology that combines differentiating prior variance (AB; Wilson 2006) with estimating Historical Weights based on Historical Probabilities (CB; Beguš 2016), whereby both variables influence the typology. I further argue that this new model performs better than the current "split" models on the basis of two alternations, post-nasal voicing and devoicing, and point to future directions this line of research should take.}, booktitle= {Proceedings of the West Coast Conference on Formal Linguistics}, pages= {104}, publisher= {Cascadilla Press}, number= {35}, year= {2017}, title= {A Formal Model of Phonological Typology}, language= {eng}, address= {Tucson}, author= {Begu\v{s}, Ga\v{s}per}, keywords= {Phonology ; Bootstrapping ; Phonology ; Bias ; Voicing}, html= {http://search.proquest.com/docview/2244647771/},
pdf={begus_17_a-formal-model.pdf}}


@article{doi:10.1121/1.5007728,
author = {Begu\v{s}, Ga\v{s}per},
title = {Effects of ejective stops on preceding vowel duration},
journal = {Journal of the Acoustical Society of America},
volume = {142},
number = {4},
pages = {2168-2184},
year = {2017},
doi = {10.1121/1.5007728},
html = {https://doi.org/10.1121/1.5007728},
eprint = {https://doi.org/10.1121/1.5007728},
abstract = {One of the most widely studied observations in linguistic phonetics is that, all else being equal, vowels are longer before voiced than before voiceless obstruents. The causes of this phonetic generalization are, however, poorly understood and several competing explanations have been proposed. No studies have so far measured vowel duration before stops with yet another laryngeal feature: ejectives. This study fills this gap and presents results from an experiment that measures vowel duration before stops with all three laryngeal features in Georgian and models effects of both closure and voice onset time (VOT) on preceding vowel duration at the same time. The results show that vowels have significantly different durations before all three series of stops, voiced, ejective, and voiceless aspirated, even when closure and VOT durations are controlled for. The results also suggest that closure and VOT durations are inversely correlated with preceding vowel duration. These results combined bear several implications for the discussion of causes of vowel duration differences: the data support the hypotheses that claim that laryngeal gestures, temporal compensation, and closure velocity affect vowel duration. Some explanations, especially perceptual and airflow expenditure explanations, are considerably weakened by the results.},
pdf={begus_effects_of_ejective_stops_on_preceding_vowel_duration_01.pdf}
}

@INPROCEEDINGS{begus16, author= {Ga\v{s}per Begu\v{s}}, address= {Bremen}, title= {The phonetics of the independent svarita in Vedic}, booktitle= {Proceedings of the 26th Annual UCLA Indo-European Conference}, year= {2016}, editor= {Stephanie W. Jamison and H. Craig Melchert and Brent Harmon Vine and Angelo Mercado}, pages= {1-12}, publisher= {Hempen}, isbn= {9783944312323},
pdf={begus_the_phonetics_of_independent_svarita_in_vedic.pdf},
html={http://www.hempen-verlag.de/sprachwissenschaften/indogermanistik/ucla-proceedings/proceedings-of-the-26th-annual-ucla-indo-european-conference.html}}


@article{begus15,title = {A new rule in vedic metrics},journal = {Journal of the American Oriental Society},year = {2015},volume = {135},number = {3},pages = {541-550},author = {Ga\v{s}per Begu\v{s}},
pdf={begus_a_new_rule_in_vedic_metrics.pdf},
abstract={In this paper I propose a new rule of Vedic meter. The glides v and y are regularly lost before the corresponding high vowels ū̆ and ī̆ in Vedic. I argue that the word-initial glides v and y before the short vowels ŭ and ĭ still “make position” and that they should be restored for metrical purposes. This means that word-final syllables of the shape -V̆C should be scanned long if the following syllable begins with a u- or i- that goes back to *vu- or *yi-. This new rule has consequences for the general metrical shape of the Rigveda, as cadences previously scanned as irregular will be repaired to their canonical shape. The rule can also be employed as etymologically decisive for words that can potentially go back to forms with or without an initial glide.},
html={http://dx.doi.org/10.7817/jameroriesoci.135.3.541},
}


@article{Beguš2015,title = {The circumflex advancement in prekmurje {S}lovenian and {B}ednja {K}ajkavian},journal = {Zeitschrift f\"ur Slawistik},year = {2015},volume = {60},number = {1},pages = {33-44},author = {Ga\v{s}per Begu\v{s}},
html={http://dx.doi.org/10.1515/slaw-2015-0003},
abstract={The circumflex advancement is usually dated after the loss of the weak jers. However, this chronology has been questioned by Vermeer (1979) and Greenberg (1992, 1993), who claim the opposite: that the weak jers were lost after the advancement. They further propose the “non-advancement rule”, by which the circumflex does not advance if a weak jer follows. Their evidence comes almost exclusively from the l-participles of the accentual paradigm c, which have the initial accent in the two dialects. The article presents new data that argue against this proposal. It is shown that the circumflex regularly advances in words outside the category of l-participles despite the presence of a subsequent weak jer. Moreover, a new explanation is given for the initial accent in l-participles that better captures the data. }} 

@article{begus11,doi = {10.17161/sls.1808.7536},url = {https://doi.org/10.17161%2Fsls.1808.7536},year = "2011",month = {jan},publisher = {The University of Kansas},author = {Ga{\v{s}}per Begu{\v{s}}},title = {Relativna kronologija naglasnih pojavov govora {\v{Z}}irovske kotline poljanskega nare{\v{c}}ja},journal = {Slovenski jezik -- Slovene Linguistic Studies},
abstract={(translation) The Žiri Basin local dialect within the Poljane dialect evinces several special features in its structure and development. Based on the system described in Stanonik (1977), the author elucidates the system’s accentual changes from Common Slovene to the present state, and also presents some new discoveries concerning the system itself that help explain the phenomena more precisely. This description helps establish a relative chronology of the accentual phenomena, the resulting model of which is compared and contrasted with other explanations. Finally, the relative chronology of accentual changes is placed in the larger context of the development of Slovene.},
pdf={begus_relativna_kronologija_naglasnih_pojavov_govora_zirovske_kotline_poljanskega_narecja.pdf},
html={http://dx.doi.org/10.17161/SLS.1808.7536}} 

@misc{begu2020ciwgan,
    title={CiwGAN and fiwGAN: Encoding information in acoustic data to model lexical learning with Generative Adversarial Networks},
    author={Ga\v{s}per Begu\v{s}},
    year={2020},
    eprint={2006.02951},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    html={https://arxiv.org/abs/2006.02951},
    abstract={How can deep neural networks encode information that corresponds to words in human speech into raw acoustic data? This paper proposes two neural network architectures for modeling unsupervised lexical learning from raw acoustic inputs, ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN), that combine a DCGAN architecture for audio data (WaveGAN; arXiv:1705.07904) with InfoGAN (arXiv:1606.03657), and propose a new latent space structure that can model featural learning simultaneously with a higher level classification. The architectures introduce a network that learns to retrieve latent codes from generated audio outputs. Lexical learning is thus modeled as emergent from an architecture that forces a deep neural network to output data such that unique information is retrievable from its acoustic outputs. The networks trained on lexical items from TIMIT learn to encode unique information corresponding to lexical items in the form of categorical variables. By manipulating these variables, the network outputs specific lexical items. Innovative outputs suggest that phonetic and phonological representations learned by the network can be productively recombined and directly paralleled to productivity in human speech: a fiwGAN network trained on 'suit' and 'dark' outputs innovative 'start', even though it never saw 'start' or even a [st] sequence in the training data. We also argue that setting latent featural codes to values well beyond training range results in almost categorical generation of prototypical lexical items and reveals underlying values of each latent code. Probing deep neural networks trained on well understood dependencies in speech bears implications for latent space interpretability, understanding how deep neural networks learn meaningful representations, as well as a potential for unsupervised text-to-speech generation in the GAN framework.},
    pdf={begus2006.02951.pdf},}


@misc{begu2020ciwgan,
    title={Identity-Based Patterns in Deep Convolutional Networks: Generative Adversarial Phonology and Reduplication},
    author={Ga\v{s}per Begu\v{s}},
    year={2020},
    eprint={2009.06110},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    html={https://arxiv.org/abs/2009.06110},
    abstract={Identity-based patterns for which a computational model needs to output some feature together with a copy of that feature are computationally challenging, but pose no problems to human learners and are common in world's languages. In this paper, we test whether a neural network can learn an identity-based pattern in speech called reduplication. To our knowledge, this is the first attempt to test identity-based patterns in deep convolutional networks trained on raw continuous data. Unlike existing proposals, we test learning in an unsupervised manner and we train the network on raw acoustic data. We use the ciwGAN architecture (Beguš 2020; arXiv:2006.02951) in which learning of meaningful representations in speech emerges from a requirement that the deep convolutional network generates informative data. Based on four generative tests, we argue that a deep convolutional network learns to represent an identity-based pattern in its latent space; by manipulating only two categorical variables in the latent space, we can actively turn an unreduplicated form into a reduplicated form with no other changes to the output in the majority of cases. We also argue that the network extends the identity-based pattern to unobserved data: when reduplication is forced in the output with the proposed technique for latent space manipulation, the network generates reduplicated data (e.g., it copies an [s] e.g. in [si-siju] for [siju] although it never sees any reduplicated forms containing an [s] in the input). Comparison with human outputs of reduplication show a high degree of similarity. Exploration of how meaningful representations of identity-based patterns emerge and how the latent space variables outside of the training range correlate with identity-based patterns in the output has general implications for neural network interpretability.},
    pdf={begus2009.06110.pdf},}
