---
---


@article{begus20,
author={Begu\v{s}, Ga\v{s}per},    
title={Generative Adversarial Phonology: Modeling Unsupervised Phonetic and Phonological Learning With Neural Networks},      	
journal={Frontiers in Artificial Intelligence},      	
volume={3},      
pages={44},     	
year={2020},      	  
url={https://www.frontiersin.org/article/10.3389/frai.2020.00044},
html={https://www.frontiersin.org/article/10.3389/frai.2020.00044},       
doi={10.3389/frai.2020.00044},      
issn={2624-8212},   
abstract={Training deep neural networks on well-understood dependencies in speech data can provide new insights into how they learn internal representations. This paper argues that acquisition of speech can be modeled as a dependency between random space and generated speech data in the Generative Adversarial Network architecture and proposes a methodology to uncover the network's internal representations that correspond to phonetic and phonological properties. The Generative Adversarial architecture is uniquely appropriate for modeling phonetic and phonological learning because the network is trained on unannotated raw acoustic data and learning is unsupervised without any language-specific assumptions or pre-assumed levels of abstraction. A Generative Adversarial Network was trained on an allophonic distribution in English, in which voiceless stops surface as aspirated word-initially before stressed vowels, except if preceded by a sibilant [s]. The network successfully learns the allophonic alternation: the network's generated speech signal contains the conditional distribution of aspiration duration. The paper proposes a technique for establishing the network's internal representations that identifies latent variables that correspond to, for example, presence of [s] and its spectral properties. By manipulating these variables, we actively control the presence of [s] and its frication amplitude in the generated outputs. This suggests that the network learns to use latent variables as an approximation of phonetic and phonological representations. Crucially, we observe that the dependencies learned in training extend beyond the training interval, which allows for additional exploration of learning representations. The paper also discusses how the network's architecture and innovative outputs resemble and differ from linguistic behavior in language acquisition, speech disorders, and speech errors, and how well-understood dependencies in speech data can help us interpret how neural networks learn their representations.},
pdf={begusGAP.pdf},
}


@inproceedings{begusscil,
    title = "Modeling unsupervised phonetic and phonological learning in {Generative Adversarial Phonology}",
    author = "Ga\v{s}per Begu\v{s}",
    booktitle = "Proceedings of the Society for Computation in Linguistics",
    year = "2020",
    url = "https://doi.org/10.7275/nbrf-1a27",
    html = "https://doi.org/10.7275/nbrf-1a27",
    doi = "10.7275/nbrf-1a27",
    pages = "138--148",
} 


@article{begus19, 
title={Post-nasal devoicing and the blurring process},
volume={55}, DOI={10.1017/S002222671800049X}, 
number={4}, 
journal={Journal of Linguistics}, 
publisher={Cambridge University Press}, 
author={Begu\v{s}, Ga\v{s}per}, 
year={2019}, pages={689–753},
html={https://www.cambridge.org/core/journals/journal-of-linguistics/article/postnasal-devoicing-and-the-blurring-process/51B1F27754D14F8BF523B905FFFE3BA1},
abstract={This paper addresses one of the most contested issues in phonology: unnatural alternations. First, non-natural phonological processes are subdivided into unmotivated and unnatural. The central topic of the paper is an unnatural process: post-nasal devoicing (PND). I collect thirteen cases of PND and argue that in all reported cases, PND does not derive from a single unnatural sound change (as claimed in some individual accounts of the data), but rather from a combination of three sound changes, each of which is phonetically motivated. I present new evidence showing that the three stages are directly historically attested in the pre-history of Yaghnobi. Based on several discussed cases, I propose a new diachronic model for explaining unnatural phenomena called the Blurring Process and point to its advantages over competing approaches (hypercorrection, perceptual enhancement, and phonetic motivation). The Blurring Process establishes general diachronic conditions for unnatural synchronic processes and can be employed to explain unnatural processes beyond PND. Additionally, I provide a proof establishing the minimal sound changes required for an unmotivated/unnatural alternation to arise. The Blurring Process and Minimal Sound Change Requirement have implications for models of typology within the Channel Bias approach. This paper thus presents a first step toward the ultimate goal of quantifying the influences of Channel Bias on phonological typology.},
}

@INPROCEEDINGS{begusnazarov18, author= {Ga\v{s}per Begu\v{s}  and Aleksei Nazarov}, title= {Gradient trends against phonetic naturalness: The case of {Tarma Quechua}}, booktitle= {NELS 48: Proceedings of the Forty-Eighth Annual Meeting of the North East Linguistic Society}, year= {2018}, editor= {Sherry Hucklebridge and Max Nelson}, volume= {1}, pages= {73-86}, publisher= {GLSA University of Massachusetts Amherst}, address= {Amherst, MA}, isbn= {978-1727605792}}


@inproceedings{begus, issn= {1042-1068}, abstract= {Identifying and modeling factors that influence typology has been one of the most contested issues in phonology with two major lines of thought emerging in this discussion: the Analytic Bias (AB) and Channel Bias (CB) approaches (Moreton 2008). Empirical evidence in favor of both approaches exists, yet very few attempts have been made to model them together. This paper aims to fill this gap and proposes a new MaxEnt-compatible model of phonological typology that models both AB and CB together. The first step towards a new model of typology is to establish quantitative models of each of the subcomponents: AB and CB. To encode the AB portion of the typology, we adopt Wilson's (2006) approach of differentiating variance in the prior of a MaxEnt model of phonological learning; to encode the CB portion, we adopt Beguš's (2016) new model of typology within CB that operates with Historical Probabilities of Alternations and an estimation method called Bootstrapping Sound Changes. This paper proposes a new model of typology that combines differentiating prior variance (AB; Wilson 2006) with estimating Historical Weights based on Historical Probabilities (CB; Beguš 2016), whereby both variables influence the typology. I further argue that this new model performs better than the current "split" models on the basis of two alternations, post-nasal voicing and devoicing, and point to future directions this line of research should take.}, booktitle= {Proceedings of the West Coast Conference on Formal Linguistics}, pages= {104}, publisher= {Cascadilla Press}, number= {35}, year= {2017}, title= {A Formal Model of Phonological Typology}, language= {eng}, address= {Tucson}, author= {Beguš, Gašper}, keywords= {Phonology ; Bootstrapping ; Phonology ; Bias ; Voicing}, html= {http://search.proquest.com/docview/2244647771/}}


@article{doi:10.1121/1.5007728,
author = {Begu\v{s}, Ga\v{s}per},
title = {Effects of ejective stops on preceding vowel duration},
journal = {Journal of the Acoustical Society of America},
volume = {142},
number = {4},
pages = {2168-2184},
year = {2017},
doi = {10.1121/1.5007728},
html = {https://doi.org/10.1121/1.5007728},
eprint = {https://doi.org/10.1121/1.5007728},
abstract = {One of the most widely studied observations in linguistic phonetics is that, all else being equal, vowels are longer before voiced than before voiceless obstruents. The causes of this phonetic generalization are, however, poorly understood and several competing explanations have been proposed. No studies have so far measured vowel duration before stops with yet another laryngeal feature: ejectives. This study fills this gap and presents results from an experiment that measures vowel duration before stops with all three laryngeal features in Georgian and models effects of both closure and voice onset time (VOT) on preceding vowel duration at the same time. The results show that vowels have significantly different durations before all three series of stops, voiced, ejective, and voiceless aspirated, even when closure and VOT durations are controlled for. The results also suggest that closure and VOT durations are inversely correlated with preceding vowel duration. These results combined bear several implications for the discussion of causes of vowel duration differences: the data support the hypotheses that claim that laryngeal gestures, temporal compensation, and closure velocity affect vowel duration. Some explanations, especially perceptual and airflow expenditure explanations, are considerably weakened by the results.},
}

@INPROCEEDINGS{begus16, author= {Ga\v{s}per Begu\v{s}}, address= {Bremen}, title= {The phonetics of the independent svarita in Vedic}, booktitle= {Proceedings of the 26th Annual UCLA Indo-European Conference}, year= {2016}, editor= {Stephanie W. Jamison and H. Craig Melchert and Brent Harmon Vine and Angelo Mercado}, pages= {1-12}, publisher= {Hempen}, isbn= {9783944312323}}


@article{begus15,title = {A new rule in vedic metrics},journal = {Journal of the American Oriental Society},year = {2015},volume = {135},number = {3},pages = {541-550},author = {Ga\v{s}per Begu\v{s}}} 



@article{Beguš2015,title = {The circumflex advancement in prekmurje {S}lovenian and {B}ednja {K}ajkavian},journal = {Zeitschrift f\"ur Slawistik},year = {2015},volume = {60},number = {1},pages = {33-44},author = {Ga\v{s}per Begu\v{s}}} 

@article{begus11,doi = {10.17161/sls.1808.7536},url = {https://doi.org/10.17161%2Fsls.1808.7536},year = "2011",month = {jan},publisher = {The University of Kansas},author = {Ga{\v{s}}per Begu{\v{s}}},title = {Relativna kronologija naglasnih pojavov govora {\v{Z}}irovske kotline poljanskega nare{\v{c}}ja},journal = {Slovenski jezik}} 
